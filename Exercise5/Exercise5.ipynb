{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Zadanie 5\n",
        "\n",
        "\n",
        "Celem ćwiczenia jest implementacja perceptronu wielowarstwowego oraz wybranego algorytmu optymalizacji gradientowej z algorytmem propagacji wstecznej.\n",
        "\n",
        "Następnie należy wytrenować perceptron wielowarstwowy do klasyfikacji zbioru danych [MNIST](http://yann.lecun.com/exdb/mnist/). Zbiór MNIST dostępny jest w pakiecie `scikit-learn`.\n",
        "\n",
        "Punktacja:\n",
        "1. Implementacja propagacji do przodu (`forward`) [1 pkt]\n",
        "2. Implementacja wstecznej propagacji (`backward`) [2 pkt]\n",
        "3. Przeprowadzenie eksperymentów na zbiorze MNIST, w tym:\n",
        "    1. Porównanie co najmniej dwóch architektur sieci [1 pkt]\n",
        "    2. Przetestowanie każdej architektury na conajmniej 3 ziarnach [1 pkt]\n",
        "    3. Wnioski [2.5 pkt]\n",
        "4. Jakość kodu [0.5 pkt]\n",
        "\n",
        "Polecane źródła - teoria + intuicja:\n",
        "1. [Karpathy, CS231n Winter 2016: Lecture 4: Backpropagation, Neural Networks 1](https://www.youtube.com/watch?v=i94OvYb6noo&ab_channel=AndrejKarpathy)\n",
        "2. [3 Blude one Brown, Backpropagation calculus | Chapter 4, Deep learning\n",
        "](https://www.youtube.com/watch?v=tIeHLnjs5U8&t=4s&ab_channel=3Blue1Brown)\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "5BPd1IecgTcc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from abc import abstractmethod, ABC\n",
        "from typing import List\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "oNmMDnkRgTcj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class Layer(ABC):\n",
        "    \"\"\"Basic building block of the Neural Network\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self._learning_rate = 0.01\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self, x:np.ndarray)->np.ndarray:\n",
        "        \"\"\"Forward propagation of x through layer\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def backward(self, output_error_derivative) ->np.ndarray:\n",
        "        \"\"\"Backward propagation of output_error_derivative through layer\"\"\"\n",
        "        pass\n",
        "\n",
        "    @property\n",
        "    def learning_rate(self):\n",
        "        return self._learning_rate\n",
        "\n",
        "    @learning_rate.setter\n",
        "    def learning_rate(self, learning_rate):\n",
        "        assert learning_rate < 1, f\"Given learning_rate={learning_rate} is larger than 1\"\n",
        "        assert learning_rate > 0, f\"Given learning_rate={learning_rate} is smaller than 0\"\n",
        "        self._learning_rate = learning_rate\n",
        "\n",
        "class FullyConnected(Layer):\n",
        "    def __init__(self, input_size:int, output_size:int) -> None:\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def forward(self, x:np.ndarray)->np.ndarray:\n",
        "        pass\n",
        "\n",
        "    def backward(self, output_error_derivative)->np.ndarray:\n",
        "        pass\n",
        "\n",
        "class Tanh(Layer):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x:np.ndarray)->np.ndarray:\n",
        "        pass\n",
        "\n",
        "    def backward(self, output_error_derivative)->np.ndarray:\n",
        "        pass\n",
        "\n",
        "class Loss:\n",
        "    def __init__(self, loss_function:callable, loss_function_derivative:callable)->None:\n",
        "        self.loss_function = loss_function\n",
        "        self.loss_function_derivative = loss_function_derivative\n",
        "\n",
        "    def loss(self, x:np.ndarray)->np.ndarray:\n",
        "        \"\"\"Loss function for a particular x\"\"\"\n",
        "        pass\n",
        "\n",
        "    def loss_derivative(self, x:np.ndarray, y:np.ndarray)->np.ndarray:\n",
        "        \"\"\"Loss function derivative for a particular x and y\"\"\"\n",
        "        pass\n",
        "\n",
        "class Network:\n",
        "    def __init__(self, layers:List[Layer], learning_rate:float)->None:\n",
        "        self.layers = layers\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def compile(self, loss:Loss)->None:\n",
        "        \"\"\"Define the loss function and loss function derivative\"\"\"\n",
        "        pass\n",
        "\n",
        "    def __call__(self, x:np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Forward propagation of x through all layers\"\"\"\n",
        "        pass\n",
        "\n",
        "    def fit(self,\n",
        "            x_train:np.ndarray,\n",
        "            y_train:np.ndarray,\n",
        "            epochs:int,\n",
        "            learning_rate:float,\n",
        "            verbose:int=0)->None:\n",
        "        \"\"\"Fit the network to the training data\"\"\"\n",
        "        pass"
      ],
      "metadata": {
        "id": "Tl6Mj5wogTcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eksperymenty"
      ],
      "metadata": {
        "collapsed": false,
        "id": "sZTneKpngTco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wnioski"
      ],
      "metadata": {
        "collapsed": false,
        "id": "UQ_vyk1bgTcp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "_VxlayEjgTcq"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}