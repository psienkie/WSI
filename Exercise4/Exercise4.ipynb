{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Zadanie 4 (7 pkt)\n",
    "Celem zadania jest zaimplementowanie algorytmu drzewa decyzyjnego ID3 dla zadania klasyfikacji. Trening i test należy przeprowadzić dla zbioru Iris. Proszę przeprowadzić eksperymenty najpierw dla DOKŁADNIE takiego podziału zbioru testowego i treningowego jak umieszczony poniżej. W dalszej części należy przeprowadzić analizę działania drzewa dla różnych wartości parametrów. Proszę korzystać z przygotowanego szkieletu programu, oczywiście można go modyfikować według potrzeb. Wszelkie elementy szkieletu zostaną wyjaśnione na zajęciach.\n",
    "\n",
    "* Implementacja funkcji entropii - **0.5 pkt**\n",
    "* Implementacja funkcji entropii zbioru - **0.5 pkt**\n",
    "* Implementacja funkcji information gain - **0.5 pkt**\n",
    "* Zbudowanie poprawnie działającego drzewa klasyfikacyjnego i przetestowanie go na wspomnianym wcześniej zbiorze testowym. Jeśli w liściu występuje kilka różnych klas, decyzją jest klasa większościowa. Policzenie accuracy i wypisanie parami klasy rzeczywistej i predykcji. - **4 pkt**\n",
    "* Przeprowadzenie eksperymentów dla różnych głębokości drzew i podziałów zbioru treningowego i testowego (zmiana wartości argumentu test_size oraz usunięcie random_state). W tym przypadku dla każdego eksperymentu należy wykonać kilka uruchomień programu i wypisać dla każdego uruchomienia accuracy. - **1.5 pkt**\n"
   ],
   "metadata": {
    "id": "cpar5LziY_-0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sympy.stats.rv import probability\n",
    "from typing import Tuple\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=123)"
   ],
   "metadata": {
    "id": "XNc-O3npA-J9",
    "ExecuteTime": {
     "end_time": "2024-12-15T22:16:28.332745Z",
     "start_time": "2024-12-15T22:16:28.322862Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "def entropy_func(class_count: int, num_samples: int) -> float:\n",
    "    probability = class_count / num_samples\n",
    "    return -probability * np.log2(probability)\n",
    "\n",
    "\n",
    "class Group:\n",
    "    def __init__(self, group_classes):\n",
    "        self.group_classes = group_classes\n",
    "        self.entropy = self.group_entropy()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.group_classes.size\n",
    "\n",
    "    def group_entropy(self) -> float:\n",
    "        _, class_counts = np.unique(self.group_classes, return_counts=True)\n",
    "        num_samples = len(self.group_classes)\n",
    "        return sum(entropy_func(count, num_samples) for count in class_counts)\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, split_feature=None, split_val=None, depth=None, child_node_a=None, child_node_b=None, val=None):\n",
    "        self.split_feature = split_feature\n",
    "        self.split_val = split_val\n",
    "        self.depth = depth\n",
    "        self.child_node_a = child_node_a\n",
    "        self.child_node_b = child_node_b\n",
    "        self.val = val\n",
    "\n",
    "    def predict(self, data: np.ndarray) -> int:\n",
    "        if self.val is not None:\n",
    "            return self.val\n",
    "        elif data[self.split_feature] >= self.split_val:\n",
    "            return self.child_node_a.predict(data)\n",
    "        else:\n",
    "            return self.child_node_b.predict(data)\n",
    "\n",
    "\n",
    "class DecisionTreeClassifier(object):\n",
    "    def __init__(self, max_depth):\n",
    "        self.depth = 0\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_split_entropy(group_a: Group, group_b: Group) -> float:\n",
    "        total_samples = len(group_a) + len(group_b)\n",
    "        return (len(group_a) / total_samples) * group_a.group_entropy() + (len(group_b) / total_samples) * group_b.group_entropy()\n",
    "\n",
    "    def get_information_gain(self, parent_group: Group, child_group_a: Group, child_group_b: Group) -> float:\n",
    "        return parent_group.group_entropy() - self.get_split_entropy(child_group_a, child_group_b)\n",
    "\n",
    "    def get_best_feature_split(self, feature_values: np.ndarray, classes: np.ndarray) -> Tuple[int, float]:\n",
    "        parent_group = Group(classes)\n",
    "        best_split_value = None\n",
    "        best_gain = -1\n",
    "        for split_feature in np.unique(feature_values):\n",
    "            a_indices = feature_values <= split_feature\n",
    "            b_indices = feature_values > split_feature\n",
    "            if not np.any(a_indices) or not np.any(b_indices):\n",
    "                continue\n",
    "\n",
    "            group_a = Group(classes[a_indices])\n",
    "            group_b = Group(classes[b_indices])\n",
    "            gain = self.get_information_gain(parent_group, group_a, group_b)\n",
    "            if gain > best_gain:\n",
    "                best_split_value = split_feature\n",
    "                best_gain = gain\n",
    "\n",
    "        return best_split_value, best_gain\n",
    "\n",
    "    def get_best_split(self, data: np.ndarray, classes: np.ndarray) -> Tuple[int, int, float]:\n",
    "        best_split_value = None\n",
    "        best_split_feature = None\n",
    "        best_gain = -1\n",
    "\n",
    "        for feature_index in range(data.shape[1]):\n",
    "            feature_values = data[:, feature_index]\n",
    "            split_value, gain = self.get_best_feature_split(feature_values, classes)\n",
    "            if gain > best_gain:\n",
    "                best_split_value = split_value\n",
    "                best_split_feature = feature_index\n",
    "                best_gain = gain\n",
    "\n",
    "        return best_split_feature, best_split_value, best_gain\n",
    "\n",
    "    def build_tree(self, data: np.ndarray, classes: np.ndarray, depth=0) -> Node:\n",
    "        if depth >= self.max_depth or len(np.unique(classes)) == 1:\n",
    "            majority_class = Counter(classes).most_common(1)[0][0]\n",
    "            return Node(val=majority_class)\n",
    "\n",
    "        split_feature, split_value, best_gain = self.get_best_split(data, classes)\n",
    "        if split_feature is None:\n",
    "            majority_class = Counter(classes).most_common(1)[0][0]\n",
    "            return Node(val=majority_class)\n",
    "\n",
    "        a_indices = data[:, split_feature] <= split_value\n",
    "        b_indices = data[:, split_feature] > split_value\n",
    "        child_node_a = self.build_tree(data[a_indices], classes[a_indices], depth + 1)\n",
    "        child_node_b = self.build_tree(data[b_indices], classes[b_indices], depth + 1)\n",
    "\n",
    "        return Node(split_feature, split_value, depth, child_node_a, child_node_b)\n",
    "\n",
    "    def fit(self, data: np.ndarray, classes: np.ndarray):\n",
    "        self.tree = self.build_tree(data, classes)\n",
    "\n",
    "    def predict(self, data: np.ndarray) -> int:\n",
    "        if self.tree is not None:\n",
    "            return self.tree.predict(data)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "id": "fBh2tfQ44u5k"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dc = DecisionTreeClassifier(3)\n",
    "dc.build_tree(x_train, y_train)\n",
    "for sample, gt in zip(x_test, y_test):\n",
    "    prediction = dc.predict(sample)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "id": "U033RY1_YS8x"
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  },
  "kernel_info": {
   "name": "python"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
